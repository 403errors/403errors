{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-02T20:37:42.216358Z","iopub.execute_input":"2024-12-02T20:37:42.217897Z","iopub.status.idle":"2024-12-02T20:37:42.226122Z","shell.execute_reply.started":"2024-12-02T20:37:42.217732Z","shell.execute_reply":"2024-12-02T20:37:42.224775Z"}},"outputs":[],"execution_count":57},{"cell_type":"markdown","source":"# PROJECT DESCRIPTION\n\nPut a youtube video link, it will generate summary of the video as well as let you ask queries related to the video.\n\n> For test run click on the \"**Run All**\" button, input the url below and you can find results in \"**Results**\" section of the notebook","metadata":{}},{"cell_type":"code","source":"yt_url = input(\"Input YouTube URL\")\n# Example: https://youtu.be/ad79nYk2keg","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T20:37:42.229539Z","iopub.execute_input":"2024-12-02T20:37:42.230903Z","iopub.status.idle":"2024-12-02T20:37:49.445989Z","shell.execute_reply.started":"2024-12-02T20:37:42.230835Z","shell.execute_reply":"2024-12-02T20:37:49.444782Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Input YouTube URL https://youtu.be/ad79nYk2keg\n"}],"execution_count":58},{"cell_type":"markdown","source":"# Importing initial packages","metadata":{}},{"cell_type":"markdown","source":"**Pakages required:**","metadata":{}},{"cell_type":"code","source":"!pip install langchain docarray==0.38.0 yt_dlp openai-whisper transformers==4.44.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T20:37:49.447709Z","iopub.execute_input":"2024-12-02T20:37:49.448200Z","iopub.status.idle":"2024-12-02T20:38:03.968219Z","shell.execute_reply.started":"2024-12-02T20:37:49.448148Z","shell.execute_reply":"2024-12-02T20:38:03.966947Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.3.9)\nRequirement already satisfied: docarray==0.38.0 in /opt/conda/lib/python3.10/site-packages (0.38.0)\nRequirement already satisfied: yt_dlp in /opt/conda/lib/python3.10/site-packages (2024.11.18)\nRequirement already satisfied: openai-whisper in /opt/conda/lib/python3.10/site-packages (20240930)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from docarray==0.38.0) (1.26.4)\nRequirement already satisfied: orjson>=3.8.2 in /opt/conda/lib/python3.10/site-packages (from docarray==0.38.0) (3.10.4)\nCollecting pydantic<2.0.0,>=1.10.2 (from docarray==0.38.0)\n  Using cached pydantic-1.10.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (152 kB)\nRequirement already satisfied: rich>=13.1.0 in /opt/conda/lib/python3.10/site-packages (from docarray==0.38.0) (13.7.1)\nRequirement already satisfied: types-requests>=2.28.11.6 in /opt/conda/lib/python3.10/site-packages (from docarray==0.38.0) (2.32.0.20241016)\nRequirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from docarray==0.38.0) (0.9.0)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.3.21)\nRequirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.3.2)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.147)\nINFO: pip is looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\nCollecting langchain\n  Using cached langchain-0.3.8-py3-none-any.whl.metadata (7.1 kB)\n  Using cached langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n  Using cached langchain-0.3.6-py3-none-any.whl.metadata (7.1 kB)\n  Using cached langchain-0.3.5-py3-none-any.whl.metadata (7.1 kB)\n  Using cached langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n  Using cached langchain-0.3.3-py3-none-any.whl.metadata (7.1 kB)\n  Using cached langchain-0.3.2-py3-none-any.whl.metadata (7.1 kB)\nINFO: pip is still looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n  Using cached langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n  Using cached langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n  Using cached langchain-0.2.17-py3-none-any.whl.metadata (7.1 kB)\nCollecting langchain-core<0.3.0,>=0.2.43 (from langchain)\n  Using cached langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\nCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n  Using cached langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.3.0)\nRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (0.60.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (2.4.0+cpu)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (4.66.4)\nRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (10.3.0)\nRequirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (0.8.0)\nRequirement already satisfied: triton>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (3.1.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.43->langchain) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.43->langchain) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.43->langchain) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.2.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.8.30)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=13.1.0->docarray==0.38.0) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=13.1.0->docarray==0.38.0) (2.18.0)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton>=2.0.0->openai-whisper) (3.15.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->docarray==0.38.0) (1.0.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->openai-whisper) (0.43.0)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2024.5.15)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (2024.6.1)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.43->langchain) (2.4)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray==0.38.0) (0.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->openai-whisper) (2.1.5)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->openai-whisper) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.0)\nUsing cached langchain-0.2.17-py3-none-any.whl (1.0 MB)\nUsing cached langchain_core-0.2.43-py3-none-any.whl (397 kB)\nUsing cached langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\nUsing cached pydantic-1.10.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\nInstalling collected packages: pydantic, langchain-core, langchain-text-splitters, langchain\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 2.10.2\n    Uninstalling pydantic-2.10.2:\n      Successfully uninstalled pydantic-2.10.2\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.21\n    Uninstalling langchain-core-0.3.21:\n      Successfully uninstalled langchain-core-0.3.21\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.2\n    Uninstalling langchain-text-splitters-0.3.2:\n      Successfully uninstalled langchain-text-splitters-0.3.2\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.9\n    Uninstalling langchain-0.3.9:\n      Successfully uninstalled langchain-0.3.9\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nalbumentations 1.4.17 requires pydantic>=2.7.0, but you have pydantic 1.10.19 which is incompatible.\nlangchain-community 0.3.9 requires langchain<0.4.0,>=0.3.8, but you have langchain 0.2.17 which is incompatible.\nlangchain-community 0.3.9 requires langchain-core<0.4.0,>=0.3.21, but you have langchain-core 0.2.43 which is incompatible.\npydantic-settings 2.6.1 requires pydantic>=2.7.0, but you have pydantic 1.10.19 which is incompatible.\nthinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.10.0 requires pydantic>=2, but you have pydantic 1.10.19 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-0.2.17 langchain-core-0.2.43 langchain-text-splitters-0.2.4 pydantic-1.10.19\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"!pip install -U langchain-community","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T20:38:03.969934Z","iopub.execute_input":"2024-12-02T20:38:03.970334Z","iopub.status.idle":"2024-12-02T20:38:17.961798Z","shell.execute_reply.started":"2024-12-02T20:38:03.970292Z","shell.execute_reply":"2024-12-02T20:38:17.960327Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain-community in /opt/conda/lib/python3.10/site-packages (0.3.9)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (3.9.5)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.4.0)\nCollecting langchain<0.4.0,>=0.3.8 (from langchain-community)\n  Using cached langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\nCollecting langchain-core<0.4.0,>=0.3.21 (from langchain-community)\n  Using cached langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.1.147)\nRequirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.6.1)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (8.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nCollecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain<0.4.0,>=0.3.8->langchain-community)\n  Using cached langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\nCollecting pydantic<3.0.0,>=2.7.4 (from langchain<0.4.0,>=0.3.8->langchain-community)\n  Using cached pydantic-2.10.2-py3-none-any.whl.metadata (170 kB)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-community) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-community) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.4)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2.2.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain-community) (2.4)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.8->langchain-community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.8->langchain-community) (2.27.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.0)\nUsing cached langchain-0.3.9-py3-none-any.whl (1.0 MB)\nUsing cached langchain_core-0.3.21-py3-none-any.whl (409 kB)\nUsing cached langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\nUsing cached pydantic-2.10.2-py3-none-any.whl (456 kB)\nInstalling collected packages: pydantic, langchain-core, langchain-text-splitters, langchain\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 1.10.19\n    Uninstalling pydantic-1.10.19:\n      Successfully uninstalled pydantic-1.10.19\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.2.43\n    Uninstalling langchain-core-0.2.43:\n      Successfully uninstalled langchain-core-0.2.43\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.2.4\n    Uninstalling langchain-text-splitters-0.2.4:\n      Successfully uninstalled langchain-text-splitters-0.2.4\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.2.17\n    Uninstalling langchain-0.2.17:\n      Successfully uninstalled langchain-0.2.17\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.10.2 which is incompatible.\ndocarray 0.38.0 requires pydantic<2.0.0,>=1.10.2, but you have pydantic 2.10.2 which is incompatible.\nthinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-0.3.9 langchain-core-0.3.21 langchain-text-splitters-0.3.2 pydantic-2.10.2\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"import os\nimport glob\nfrom pathlib import Path\nimport yt_dlp \nimport whisper","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T20:38:17.965097Z","iopub.execute_input":"2024-12-02T20:38:17.965515Z","iopub.status.idle":"2024-12-02T20:38:17.971719Z","shell.execute_reply.started":"2024-12-02T20:38:17.965467Z","shell.execute_reply":"2024-12-02T20:38:17.970223Z"}},"outputs":[],"execution_count":61},{"cell_type":"markdown","source":"# Download Audio","metadata":{}},{"cell_type":"code","source":"def download_audio(yt_url):\n\n    # Create a directory to save the downloaded audio files\n    output_dir = \"/kaggle/working/files/audio\"\n    Path(output_dir).mkdir(parents=True, exist_ok=True)\n\n    # yt-dlp configuration\n    ydl_config = {\n        \"format\": \"bestaudio/best\",  # Best audio quality available\n        \"postprocessors\": [\n            {\n                \"key\": \"FFmpegExtractAudio\",  # Use FFmpeg for audio extraction\n                \"preferredcodec\": \"wav\",     # Save as wav format\n                \"preferredquality\": \"192\",   # Optional, relevant for codecs like mp3\n            }\n        ],\n        \"outtmpl\": os.path.join(output_dir, \"%(title)s.%(ext)s\"),  # Save file with title as name\n        \"verbose\": True  # Show download progress in output\n    }\n    \n    print(f\"Downloading audio from {yt_url}\")\n    \n    # Attempt to download the audio\n    try:\n        with yt_dlp.YoutubeDL(ydl_config) as ydl:\n            ydl.download([yt_url])\n            print(\"Downloading successful!\")\n    except Exception as e:\n        print(f\"Error downloading audio: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T20:38:17.973665Z","iopub.execute_input":"2024-12-02T20:38:17.974220Z","iopub.status.idle":"2024-12-02T20:38:17.993019Z","shell.execute_reply.started":"2024-12-02T20:38:17.974153Z","shell.execute_reply":"2024-12-02T20:38:17.991755Z"}},"outputs":[],"execution_count":62},{"cell_type":"markdown","source":"# Transcription of downloaded audio file","metadata":{}},{"cell_type":"code","source":"def get_audiofile_path():\n    # finding all downloaded mp3 files\n    audio_file = glob.glob(os.path.join(output_dir, \"*.wav\"))\n    \n    # selecting first file (recent one)\n    audio_filepath = audio_file[-1]\n    \n    return audio_filepath","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T20:38:17.994644Z","iopub.execute_input":"2024-12-02T20:38:17.995086Z","iopub.status.idle":"2024-12-02T20:38:18.010715Z","shell.execute_reply.started":"2024-12-02T20:38:17.995035Z","shell.execute_reply":"2024-12-02T20:38:18.009412Z"}},"outputs":[],"execution_count":63},{"cell_type":"markdown","source":"# Whisper to transcribe","metadata":{}},{"cell_type":"code","source":"# to ignore unecessary warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning, module=\"whisper\")\nwarnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"torch\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T20:38:18.011978Z","iopub.execute_input":"2024-12-02T20:38:18.012356Z","iopub.status.idle":"2024-12-02T20:38:18.027290Z","shell.execute_reply.started":"2024-12-02T20:38:18.012323Z","shell.execute_reply":"2024-12-02T20:38:18.026220Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"def transcribe_with_whisper(audio_path):\n    model = whisper.load_model(\"small\")  # small - low accuracy, high speed; medium; large\n    result = model.transcribe(audio_path)\n    return result['text']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T20:38:18.028800Z","iopub.execute_input":"2024-12-02T20:38:18.029130Z","iopub.status.idle":"2024-12-02T20:38:18.041336Z","shell.execute_reply.started":"2024-12-02T20:38:18.029099Z","shell.execute_reply":"2024-12-02T20:38:18.040098Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"def save_text(text, output_dir):  \n    # Write the string to the file\n    with open(output_dir, \"w\") as file:\n        file.write(text)\n    \n    print(f\"Text successfully saved to {output_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T20:38:18.042850Z","iopub.execute_input":"2024-12-02T20:38:18.043195Z","iopub.status.idle":"2024-12-02T20:38:18.056233Z","shell.execute_reply.started":"2024-12-02T20:38:18.043161Z","shell.execute_reply":"2024-12-02T20:38:18.055043Z"}},"outputs":[],"execution_count":66},{"cell_type":"markdown","source":"# Summary Generation\n\nTextLoader (langchain) -> tokenisation -> summary pipeline -> output","metadata":{}},{"cell_type":"code","source":"from langchain.document_loaders import TextLoader\nfrom transformers import pipeline, T5Tokenizer\nimport tiktoken  # OpenAI's tokenizer for token count\nfrom math import ceil\n\n# Load the summarization pipeline (using Hugging Face T5 model in this example)\nsummarizer = pipeline(\"summarization\", model=\"t5-small\")\n\n# Load the T5 tokenizer (for token count)\ntokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n\n# Function to split text into chunks based on token count using T5's tokenizer\ndef split_text_into_chunks(text, max_tokens=512):\n    # Encode the text to get the token IDs\n    tokens = tokenizer.encode(text)\n    \n    # Calculate how many chunks are needed\n    num_chunks = ceil(len(tokens) / max_tokens)\n    chunks = []\n\n    for i in range(num_chunks):\n        # Slice the tokens into chunks of max_tokens length\n        chunk = tokens[i * max_tokens: (i + 1) * max_tokens]\n        \n        # Check if the chunk is within the allowed limit (512 tokens including special tokens)\n        # If the chunk is larger than the max tokens, we truncate it\n        if len(chunk) > max_tokens:\n            chunk = chunk[:max_tokens]\n        \n        # Decode the chunk and append to chunks list\n        decoded_chunk = tokenizer.decode(chunk, skip_special_tokens=True)\n\n        chunks.append(decoded_chunk)\n    \n    return chunks\n\ndef generate_summary(file_path):\n    # Load text file using TextLoader\n    loader = TextLoader(file_path)\n    documents = loader.load()\n    \n    # Get the text content from the loaded documents\n    text = documents[0].page_content  # Assuming it's the first document if multiple\n    \n    # Split the text into manageable chunks (adjust max_tokens to your model's limit)\n    chunks = split_text_into_chunks(text, max_tokens=505)\n    \n    # Summarize each chunk individually\n    summaries = []\n    for chunk in chunks:\n        # Handle potential issues with empty chunks or excessive length\n        if len(chunk.strip()) > 0:\n            summary = summarizer(chunk)\n            summaries.append(summary[0]['summary_text'])\n    \n    # Combine all the summaries to get the final result\n    final_summary = \" \".join(summaries)\n\n    print(\"Summary generated succesfully!\")\n    return final_summary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T20:38:18.058234Z","iopub.execute_input":"2024-12-02T20:38:18.058670Z","iopub.status.idle":"2024-12-02T20:38:19.892762Z","shell.execute_reply.started":"2024-12-02T20:38:18.058629Z","shell.execute_reply":"2024-12-02T20:38:19.891522Z"}},"outputs":[],"execution_count":67},{"cell_type":"markdown","source":"**Creating document search**","metadata":{}},{"cell_type":"code","source":"def qa(file_path, question):\n    # Use a standard QA model for plain text (SQuAD fine-tuned)\n    qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n\n    warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"transformers\")\n    \n    # Function to read text from the file\n    def read_text_from_file(file_path):\n        with open(file_path, 'r', encoding='utf-8') as file:\n            return file.read()\n    \n    # Function to answer a question from the document (text file)\n    def answer_question_from_text(text, question):\n        # Use the pipeline to get the answer from the context (text file)\n        answer = qa_pipeline(question=question, context=text)\n        return answer['answer']\n    \n    text = read_text_from_file(file_path)\n    answer = answer_question_from_text(text, question)\n    \n    return \"Answer:\"+answer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T20:50:38.197917Z","iopub.execute_input":"2024-12-02T20:50:38.198378Z","iopub.status.idle":"2024-12-02T20:50:38.207009Z","shell.execute_reply.started":"2024-12-02T20:50:38.198330Z","shell.execute_reply":"2024-12-02T20:50:38.205412Z"}},"outputs":[],"execution_count":80},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"code","source":"download_audio(yt_url)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T20:38:46.580495Z","iopub.execute_input":"2024-12-02T20:38:46.580894Z","iopub.status.idle":"2024-12-02T20:38:50.616161Z","shell.execute_reply.started":"2024-12-02T20:38:46.580862Z","shell.execute_reply":"2024-12-02T20:38:50.614970Z"}},"outputs":[{"name":"stderr","text":"[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n[debug] yt-dlp version stable@2024.11.18 from yt-dlp/yt-dlp [7ea278792] (pip) API\n[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'wav', 'preferredquality': '192'}], 'outtmpl': '/kaggle/working/files/audio/%(title)s.%(ext)s', 'verbose': True, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.61 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}}\n[debug] Python 3.10.14 (CPython x86_64 64bit) - Linux-6.6.56+-x86_64-with-glibc2.31 (OpenSSL 3.3.2 3 Sep 2024, glibc 2.31)\n[debug] exe versions: ffmpeg 4.2.7, ffprobe 4.2.7\n[debug] Optional libraries: brotli-None, certifi-2024.08.30, pycrypto-3.20.0, requests-2.32.3, secretstorage-3.3.3, sqlite3-3.46.1, urllib3-2.2.3, websockets-12.0\n[debug] Proxy map: {}\n[debug] Request Handlers: urllib, requests\n[debug] Loaded 1837 extractors\n","output_type":"stream"},{"name":"stdout","text":"Downloading audio from https://youtu.be/ad79nYk2keg\n[youtube] Extracting URL: https://youtu.be/ad79nYk2keg\n[youtube] ad79nYk2keg: Downloading webpage\n[youtube] ad79nYk2keg: Downloading ios player API JSON\n[youtube] ad79nYk2keg: Downloading mweb player API JSON\n","output_type":"stream"},{"name":"stderr","text":"[debug] Loading youtube-nsig.b46bb280 from cache\n[debug] [youtube] Decrypted nsig 8tg3Tlv-8MZGSQp_xiS => ItvNEIjqSKmsMg\n","output_type":"stream"},{"name":"stdout","text":"[youtube] ad79nYk2keg: Downloading m3u8 information\n","output_type":"stream"},{"name":"stderr","text":"[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec, channels, acodec, lang, proto\n[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec, channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n","output_type":"stream"},{"name":"stdout","text":"[info] ad79nYk2keg: Downloading 1 format(s): 251\n","output_type":"stream"},{"name":"stderr","text":"[debug] Invoking http downloader on \"https://rr4---sn-un57enez.googlevideo.com/videoplayback?expire=1733193527&ei=1xpOZ_j-COXgs8IPhNLtsAo&ip=34.80.255.247&id=o-ADVTXnOiDI1Bx1bQXMRpFcKV4iOvKfbT7E9JcNJ5TJTb&itag=251&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&met=1733171927%2C&mh=zv&mm=31%2C26&mn=sn-un57enez%2Csn-a5meknzs&ms=au%2Conr&mv=u&mvi=4&pl=25&rms=au%2Cau&bui=AQn3pFTWYB0yB2EKENneO7anp09xS_TKm_2b90GyYRgBIJ1ApQOXNAA0x2tsAIK36D97m1FeuksY5qIQ&spc=qtApAT8Np6yvRTCG48Xbb9fFx6mXfrL7CC_0N0jQ53OVogY&vprv=1&svpuc=1&mime=audio%2Fwebm&rqh=1&gir=yes&clen=5664807&dur=327.821&lmt=1712140764252870&mt=1733171383&fvip=1&keepalive=yes&fexp=51326932%2C51335594&c=IOS&txp=4532434&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cbui%2Cspc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRQIhAK0gudk57QfYWRKDBRGJptJhOzYAi8uZsYed41G5mS_0AiAmT9wQznbPeSth0Y7ncoIclNvUBc-q1g_a1oZgDeo-sg%3D%3D&lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms&lsig=AGluJ3MwRQIhAKEMw-2DjDuzj9NVIV3pd5_L19385Qnm_2GNzq3XWAvnAiBFk7oXCcm0DiRAydlBMv7QEWb9hFO2oW5PPT7_3ExAWQ%3D%3D\"\n","output_type":"stream"},{"name":"stdout","text":"[download] Destination: /kaggle/working/files/audio/What Is AI？ ｜ Artificial Intelligence ｜ What is Artificial Intelligence？ ｜ AI In 5 Mins ｜Simplilearn.webm\n[download] 100% of    5.40MiB in 00:00:00 at 27.79MiB/s  \n","output_type":"stream"},{"name":"stderr","text":"[debug] ffmpeg command line: ffprobe -show_streams 'file:/kaggle/working/files/audio/What Is AI？ ｜ Artificial Intelligence ｜ What is Artificial Intelligence？ ｜ AI In 5 Mins ｜Simplilearn.webm'\n","output_type":"stream"},{"name":"stdout","text":"[ExtractAudio] Destination: /kaggle/working/files/audio/What Is AI？ ｜ Artificial Intelligence ｜ What is Artificial Intelligence？ ｜ AI In 5 Mins ｜Simplilearn.wav\n","output_type":"stream"},{"name":"stderr","text":"[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:/kaggle/working/files/audio/What Is AI？ ｜ Artificial Intelligence ｜ What is Artificial Intelligence？ ｜ AI In 5 Mins ｜Simplilearn.webm' -vn -b:a 192.0k -movflags +faststart 'file:/kaggle/working/files/audio/What Is AI？ ｜ Artificial Intelligence ｜ What is Artificial Intelligence？ ｜ AI In 5 Mins ｜Simplilearn.wav'\n","output_type":"stream"},{"name":"stdout","text":"Deleting original file /kaggle/working/files/audio/What Is AI？ ｜ Artificial Intelligence ｜ What is Artificial Intelligence？ ｜ AI In 5 Mins ｜Simplilearn.webm (pass -k to keep)\nDownloading successful!\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"## it's processing time depends upon the length of the youtube video link you provide\n\naudio_filepath = get_audiofile_path()\ntranscribed_text = transcribe_with_whisper(audio_filepath)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T20:39:04.968307Z","iopub.execute_input":"2024-12-02T20:39:04.968741Z","iopub.status.idle":"2024-12-02T20:41:14.771220Z","shell.execute_reply.started":"2024-12-02T20:39:04.968702Z","shell.execute_reply":"2024-12-02T20:41:14.770003Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(fp, map_location=device)\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"# preview of transcribed file\ntranscribed_text[:len(transcribed_text)//10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T20:41:17.966916Z","iopub.execute_input":"2024-12-02T20:41:17.967333Z","iopub.status.idle":"2024-12-02T20:41:17.976120Z","shell.execute_reply.started":"2024-12-02T20:41:17.967293Z","shell.execute_reply":"2024-12-02T20:41:17.974829Z"}},"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"\" Picture this, a machine that could organize your cupboard just as you like it, or serve every member of the house a customized cup of coffee. Makes your day easier, doesn't it? These are the products of artificial intelligence. But why use the term artificial intelligence? Well, these machines are artificially incorporated with human-like intelligence to perform tasks as we do. This intelligence is built using complex algorithm\""},"metadata":{}}],"execution_count":72},{"cell_type":"code","source":"# to save transcribed text in output directory, return\noutput_dir = \"/kaggle/working/files/output.txt\"\ntext = transcribed_text\nsave_text(text, output_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T20:41:21.104743Z","iopub.execute_input":"2024-12-02T20:41:21.105169Z","iopub.status.idle":"2024-12-02T20:41:21.112257Z","shell.execute_reply.started":"2024-12-02T20:41:21.105123Z","shell.execute_reply":"2024-12-02T20:41:21.110997Z"}},"outputs":[{"name":"stdout","text":"Text successfully saved to /kaggle/working/files/output.txt\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"file_path = output_dir\nsummary = generate_summary(file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T20:41:24.665692Z","iopub.execute_input":"2024-12-02T20:41:24.666148Z","iopub.status.idle":"2024-12-02T20:41:31.471008Z","shell.execute_reply.started":"2024-12-02T20:41:24.666111Z","shell.execute_reply":"2024-12-02T20:41:31.469868Z"}},"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (1006 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"Summary generated succesfully!\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"print(summary)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T20:41:35.170352Z","iopub.execute_input":"2024-12-02T20:41:35.170869Z","iopub.status.idle":"2024-12-02T20:41:35.178342Z","shell.execute_reply.started":"2024-12-02T20:41:35.170797Z","shell.execute_reply":"2024-12-02T20:41:35.176980Z"}},"outputs":[{"name":"stdout","text":"artificial intelligence is used in smartphones, cars, social media feeds, video games, banking, surveillance, and many other aspects of our daily life . the robot is now at a crossroad, one that is paved, and the other, rocky . this portrays the robot's reasoning ability . AI is a subset of machine learning and deep learning . deep learning allows a machine to learn from data and experience through algorithms . this means, through deep learning, data and patterns can be better perceived . three lucky winners will receive Amazon gift vouchers .\n","output_type":"stream"}],"execution_count":75},{"cell_type":"code","source":"num_of_questiones = 3\nwhile num_of_questiones:\n    question = input(\"What is your question: \")\n    # Example: What is the topic?\n    num_of_questiones -= 1\n    print(qa(file_path, question))\n\n# As this only fetches answer from the video provided,hence if you ask anything \n# that is not been mentioned in the video, you possibly might get wrong answer!\n\n# for exmapple I'll ask two questions within the video and 1 outside of the video\n# see how it can't recognise the cons as it wasn't mentioned in the video","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T21:01:39.788439Z","iopub.execute_input":"2024-12-02T21:01:39.788872Z","iopub.status.idle":"2024-12-02T21:02:23.737571Z","shell.execute_reply.started":"2024-12-02T21:01:39.788804Z","shell.execute_reply":"2024-12-02T21:02:23.736013Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"What is your question:  What is the topic of the video\n"},{"name":"stdout","text":"Answer:artificial intelligence\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"What is your question:  What are the pros of AI\n"},{"name":"stdout","text":"Answer:AI provides machines with the capability to adapt, reason, and provide solutions\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"What is your question:  What are the cons of AI\n"},{"name":"stdout","text":"Answer:AI provides machines with the capability to adapt, reason, and provide solutions\n","output_type":"stream"}],"execution_count":85},{"cell_type":"markdown","source":"# Further scope of improvements\n\n- Training model with multiple videos or can say make a customised question answer model by putting the topic name and automatically fetching top 10 video about the topic and save the model for any queries related to the topic\n- Can be further improved by reinforcement learning","metadata":{}}]}